# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Maven build

on:
  workflow_dispatch:
  push:
    branches: [ master ]
  #pull_request:
    #branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    
    #- name: Set up Cloud SDK
      #uses: google-github-actions/setup-gcloud@master
      #with:
        #project_id: ${{ secrets.GCP_PROJECT_ID }}
        #service_account_key: ${{ secrets.GCP_ARTIFACTORY_SERVICE_ACCOUNT}}
        #export_default_credentials: true
        
    - id: 'auth'
      uses: 'google-github-actions/auth@v0'
      with:
        credentials_json: '${{ secrets.GCP_ARTIFACTORY_SERVICE_ACCOUNT }}'

    - name: 'Set up Cloud SDK'
      uses: 'google-github-actions/setup-gcloud@v0'
      
    - name: Set up JDK 1.8
      uses: actions/setup-java@v2
      with:
        java-version: '8'
        distribution: 'adopt'
        cache: maven
        
    - name: Build with Maven
      run: mvn -B package --file pom.xml
      #run: mvn clean deploy --file pom.xml

    - name: Copy to bucket
      run: gsutil cp target/spark-mvn-scala-*-jar-with-dependencies.jar gs://${{ secrets.GCP_BUCKET_ID }}/SparkJar/

    - name: starting up the dataproc cluster
      run: gcloud dataproc clusters start ${{ secrets.GCP_DATAPROC_CLUSTER }} --region=${{ secrets.GCP_REGION }}

    - name: Submit the job to dataproc cluster
      run : gcloud dataproc jobs submit spark --cluster=${{ secrets.GCP_DATAPROC_CLUSTER }} --region=${{ secrets.GCP_REGION }} --class=org.example.App --jars=gs://${{ secrets.GCP_BUCKET_ID }}/SparkJar/spark-mvn-scala-1.0-SNAPSHOT-jar-with-dependencies.jar

    - name: stopping the dataproc cluster
      if: ${{ always() }}
      run: gcloud dataproc clusters stop ${{ secrets.GCP_DATAPROC_CLUSTER }} --region=${{ secrets.GCP_REGION }}



